{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_access_key = os.environ[\"AWS_ACCESS_KEY\"]\n",
    "aws_secret_key = os.environ[\"AWS_SECRET_KEY\"]\n",
    "aws_region = os.environ[\"AWS_REGION\"]\n",
    "warehouse_location = os.environ[\"WAREHOUSE_LOCATION\"]\n",
    "metastore_uri = os.environ[\"METASTORE_URI\"]\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Warehouse\")\\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", aws_access_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", aws_secret_key) \\\n",
    "    .config(\"spark.sql.catalogImplementation\", \"hive\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_location) \\\n",
    "    .config(\"spark.sql.hive.metastore.uris\", metastore_uri) \\\n",
    "    .config(\"hive.metastore.uris\", metastore_uri) \\\n",
    "    .config(\"hive.metastore.warehouse.dir\", warehouse_location) \\\n",
    "    .config(\"hive.hadoop.fs.s3a.access.key\", aws_access_key) \\\n",
    "    .config(\"hive.hadoop.fs.s3a.secret.key\", aws_secret_key) \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.driver.memory\", \"5G\") \\\n",
    "    .config(\"spark.memory.offHeap.size\",\"16g\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\", True) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"drop schema if exists facts cascade\")\n",
    "spark.sql(\"drop database if exists dimensions cascade\")\n",
    "spark.sql(\"drop database if exists craigslist_vehicles_bronze cascade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create schema if not exists craigslist_vehicles_bronze\")\n",
    "spark.sql(\"create schema if not exists facts\")\n",
    "spark.sql(\"create database if not exists dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sCreate Delta table for raw Craigslist vehicle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"create table if not exists craigslist_vehicles_bronze.craigslist_vehicles (\n",
    "    id string, \n",
    "    region string, \n",
    "    price double, \n",
    "    year DATE, \n",
    "    manufacturer string, \n",
    "    model string, \n",
    "    condition string, \n",
    "    cylinders string, \n",
    "    fuel string, \n",
    "    odometer string, \n",
    "    title_status string, \n",
    "    transmission string, \n",
    "    drive string, \n",
    "    size string, \n",
    "    type string, \n",
    "    paint_color string, \n",
    "    state string, \n",
    "    lat double, \n",
    "    long double\n",
    "  ) using delta\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Delta tables for aggregated facts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "create table if not exists facts.year_id_price (\n",
    "        year DATE,\n",
    "        id string,\n",
    "        price double,\n",
    "        state string\n",
    "    ) using delta\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "create table if not exists facts.year_id (\n",
    "  id string,\n",
    "  year DATE,\n",
    "  state string\n",
    ") using delta\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "create table if not exists facts.manufacturer_year (\n",
    "    id string,\n",
    "    manufacturer string,\n",
    "    year DATE,\n",
    "    state string\n",
    "    ) using delta\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "create table if not exists facts.region_year (\n",
    "    id string,\n",
    "    year DATE,\n",
    "    state string\n",
    "    ) using delta\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "create table if not exists facts.region_year (\n",
    "    id string,\n",
    "    year DATE,\n",
    "    state string,\n",
    "    manufacturer string\n",
    "    ) using delta\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "create table if not exists facts.region_year (\n",
    "    id string,\n",
    "    year DATE,\n",
    "    region string,\n",
    "    state string,\n",
    "    model string\n",
    "    ) using delta\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Delta tables for dimension data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS dimensions.dates (\n",
    "    date DATE,\n",
    "    id STRING\n",
    ") USING DELTA \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS dimensions.regions (\n",
    "    region STRING,\n",
    "    id STRING\n",
    ") USING DELTA\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS dimensions.manufacturers (\n",
    "    manufacturer STRING,\n",
    "    id STRING\n",
    ") USING DELTA\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS dimensions.model (\n",
    "    model STRING,\n",
    "    id STRING\n",
    ") USING DELTA\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS dimensions.model (\n",
    "    state STRING,\n",
    "    id STRING\n",
    ") USING DELTA\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS dimensions.model (\n",
    "    manufacturer STRING,\n",
    "    id STRING\n",
    ") USING DELTA\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|namespace                 |\n",
      "+--------------------------+\n",
      "|craigslist_vehicles_bronze|\n",
      "|default                   |\n",
      "|dimensions                |\n",
      "|facts                     |\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
